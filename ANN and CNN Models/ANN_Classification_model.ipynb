{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Classification model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f-ixfapj6sW",
        "colab_type": "text"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmf4ACZkpz54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntTuhnrlKQ-4",
        "colab_type": "text"
      },
      "source": [
        "# Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-IPcy_f1iF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Read dataset\n",
        "Data = pd.read_csv('classify_data.csv',',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps3wGJO7hC_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7HPWOEj_oYc",
        "colab_type": "text"
      },
      "source": [
        "# Classification model in training, validating and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbAk9gUmfoYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Split the data to training dataset (80%), testing (10%) and validating (10%) dataset(x and y)\n",
        "fn_data_x = Data.iloc[:,:-1].to_numpy()\n",
        "fn_data_y = Data['Label'].to_numpy()\n",
        "X_train, xtv, y_train, ytv = train_test_split(fn_data_x, fn_data_y, test_size = 0.2, shuffle = True, random_state = 2019)\n",
        "X_vali, X_test, y_vali, y_test = train_test_split(xtv, ytv, test_size = 0.5, shuffle = True, random_state = 2019)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSbDUo0oK4nz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "f73ddb9b-0ccc-414d-c413-2c37f71c7296"
      },
      "source": [
        "## Bilud model\n",
        "nn_model = Sequential()\n",
        "nn_model.add(Dense(2, input_dim=18, activation='sigmoid')) #  input layer and first hidden layer\n",
        "# nn_model.add(Dense(3, activation='sigmoid')) # second hidden layer\n",
        "# nn_model.add(Dense(6, activation='sigmoid')) # third hidden layer\n",
        "nn_model.add(Dense(1, activation='sigmoid')) # output layer\n",
        "print(nn_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 2)                 38        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5QCxUcqvfbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e4b7a3c-af89-4202-abbf-f4f97ed983ef"
      },
      "source": [
        "## Training and testing model\n",
        "start = time.time()\n",
        "path_model='Cl_2_model_filter_lr0.1_mo0.8_SGD_100.h5' # save model at this location after each epoch\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.8)\n",
        "nn_model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "history = nn_model.fit(X_train, y_train, \n",
        "                       epochs=100, \n",
        "                       batch_size=5, \n",
        "                       verbose=1,\n",
        "                       validation_data=(X_vali,y_vali), \n",
        "                       callbacks=[ModelCheckpoint(filepath=path_model)], shuffle=True) # callbacks=[early_stop]\n",
        "end = time.time()\n",
        "running_time = end-start\n",
        "print('time cost : %.5f sec' %running_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.9137 - val_loss: 0.0502 - val_accuracy: 0.9900\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.8893e-04 - accuracy: 1.0000 - val_loss: 9.8096e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.5112e-04 - accuracy: 1.0000 - val_loss: 9.4434e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.1610e-04 - accuracy: 1.0000 - val_loss: 9.1036e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.8358e-04 - accuracy: 1.0000 - val_loss: 8.7868e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.5329e-04 - accuracy: 1.0000 - val_loss: 8.4922e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.2500e-04 - accuracy: 1.0000 - val_loss: 8.2161e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.9852e-04 - accuracy: 1.0000 - val_loss: 7.9586e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7371e-04 - accuracy: 1.0000 - val_loss: 7.7154e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5036e-04 - accuracy: 1.0000 - val_loss: 7.4919e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.2841e-04 - accuracy: 1.0000 - val_loss: 7.2727e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.0772e-04 - accuracy: 1.0000 - val_loss: 7.0697e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.8815e-04 - accuracy: 1.0000 - val_loss: 6.8781e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6964e-04 - accuracy: 1.0000 - val_loss: 6.6970e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5211e-04 - accuracy: 1.0000 - val_loss: 6.5249e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3546e-04 - accuracy: 1.0000 - val_loss: 6.3617e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.1967e-04 - accuracy: 1.0000 - val_loss: 6.2065e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.0463e-04 - accuracy: 1.0000 - val_loss: 6.0587e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.9030e-04 - accuracy: 1.0000 - val_loss: 5.9173e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.7665e-04 - accuracy: 1.0000 - val_loss: 5.7824e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6360e-04 - accuracy: 1.0000 - val_loss: 5.6541e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.5113e-04 - accuracy: 1.0000 - val_loss: 5.5312e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3921e-04 - accuracy: 1.0000 - val_loss: 5.4136e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2780e-04 - accuracy: 1.0000 - val_loss: 5.3008e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.1685e-04 - accuracy: 1.0000 - val_loss: 5.1930e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0634e-04 - accuracy: 1.0000 - val_loss: 5.0894e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.9626e-04 - accuracy: 1.0000 - val_loss: 4.9904e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8658e-04 - accuracy: 1.0000 - val_loss: 4.8938e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.7726e-04 - accuracy: 1.0000 - val_loss: 4.8017e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.6830e-04 - accuracy: 1.0000 - val_loss: 4.7131e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5967e-04 - accuracy: 1.0000 - val_loss: 4.6304e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5134e-04 - accuracy: 1.0000 - val_loss: 4.5454e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.4332e-04 - accuracy: 1.0000 - val_loss: 4.4661e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3558e-04 - accuracy: 1.0000 - val_loss: 4.3893e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2810e-04 - accuracy: 1.0000 - val_loss: 4.3155e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2088e-04 - accuracy: 1.0000 - val_loss: 4.2443e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1390e-04 - accuracy: 1.0000 - val_loss: 4.1747e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0714e-04 - accuracy: 1.0000 - val_loss: 4.1078e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0060e-04 - accuracy: 1.0000 - val_loss: 4.0430e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9427e-04 - accuracy: 1.0000 - val_loss: 3.9802e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8814e-04 - accuracy: 1.0000 - val_loss: 3.9194e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8219e-04 - accuracy: 1.0000 - val_loss: 3.8606e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7642e-04 - accuracy: 1.0000 - val_loss: 3.8032e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7083e-04 - accuracy: 1.0000 - val_loss: 3.7477e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6540e-04 - accuracy: 1.0000 - val_loss: 3.6938e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6013e-04 - accuracy: 1.0000 - val_loss: 3.6416e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5500e-04 - accuracy: 1.0000 - val_loss: 3.5919e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5002e-04 - accuracy: 1.0000 - val_loss: 3.5412e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.4519e-04 - accuracy: 1.0000 - val_loss: 3.4931e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.4048e-04 - accuracy: 1.0000 - val_loss: 3.4465e-04 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3590e-04 - accuracy: 1.0000 - val_loss: 3.4011e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3144e-04 - accuracy: 1.0000 - val_loss: 3.3567e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2709e-04 - accuracy: 1.0000 - val_loss: 3.3136e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2286e-04 - accuracy: 1.0000 - val_loss: 3.2716e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1874e-04 - accuracy: 1.0000 - val_loss: 3.2306e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1473e-04 - accuracy: 1.0000 - val_loss: 3.1908e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1081e-04 - accuracy: 1.0000 - val_loss: 3.1518e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0699e-04 - accuracy: 1.0000 - val_loss: 3.1139e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0326e-04 - accuracy: 1.0000 - val_loss: 3.0768e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9962e-04 - accuracy: 1.0000 - val_loss: 3.0407e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9607e-04 - accuracy: 1.0000 - val_loss: 3.0055e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9260e-04 - accuracy: 1.0000 - val_loss: 2.9709e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8921e-04 - accuracy: 1.0000 - val_loss: 2.9373e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8591e-04 - accuracy: 1.0000 - val_loss: 2.9043e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8267e-04 - accuracy: 1.0000 - val_loss: 2.8722e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7951e-04 - accuracy: 1.0000 - val_loss: 2.8408e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7641e-04 - accuracy: 1.0000 - val_loss: 2.8100e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7339e-04 - accuracy: 1.0000 - val_loss: 2.7798e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7043e-04 - accuracy: 1.0000 - val_loss: 2.7504e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6753e-04 - accuracy: 1.0000 - val_loss: 2.7217e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6470e-04 - accuracy: 1.0000 - val_loss: 2.6934e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6193e-04 - accuracy: 1.0000 - val_loss: 2.6659e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5921e-04 - accuracy: 1.0000 - val_loss: 2.6388e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5655e-04 - accuracy: 1.0000 - val_loss: 2.6123e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5394e-04 - accuracy: 1.0000 - val_loss: 2.5864e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5139e-04 - accuracy: 1.0000 - val_loss: 2.5610e-04 - val_accuracy: 1.0000\n",
            "time cost : 33.23777 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaFUQBx2nZ-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "d164abbe-660f-4f28-f172-13409341e012"
      },
      "source": [
        "## Visulize the Result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "acc = history.history.get('accuracy')\n",
        "val_acc = history.history.get('val_accuracy')\n",
        "plt.plot(range(len(acc)), acc, label='Training Accuracy')\n",
        "plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right',fontsize=12)\n",
        "plt.title('Accuracy',fontsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XLINHnAm9xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the result to csv file\n",
        "acc_df = pd.DataFrame(acc)\n",
        "val_acc_df = pd.DataFrame(val_acc)\n",
        "acc_df.to_csv('2_train_acc_lr0.1_mo0.8_SGD_100.csv', index = False) \n",
        "val_acc_df.to_csv('2_validate_acc_lr0.1_mo0.8_SGD_100.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsMpC3u4vmUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0afc5b5c-399d-4686-bfe1-09b022d9f658"
      },
      "source": [
        "# print out the accuracy\n",
        "score_train = nn_model.evaluate(X_train, y_train, verbose=0)\n",
        "score_vali = nn_model.evaluate(X_vali, y_vali, verbose=0)\n",
        "score_test = nn_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy Score on Training data: {}\".format(score_train[1]))\n",
        "print(\"Accuracy Score on Validating data: {}\".format(score_vali[1]))\n",
        "print(\"Accuracy Score on Testing data: {}\".format(score_test[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score on Training data: 1.0\n",
            "Accuracy Score on Validating data: 1.0\n",
            "Accuracy Score on Testing data: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiAUQvtqd4X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the result to csv file\n",
        "y_pred_vali_nn = nn_model.predict_classes(X_vali)\n",
        "y_pred_train_nn = nn_model.predict_classes(X_train)\n",
        "y_pred_test_nn = nn_model.predict_classes(X_test)\n",
        "y1 = pd.DataFrame(y_train, columns=['y_true(train)'])\n",
        "y2 = pd.DataFrame(y_pred_train_nn, columns=['y_predict(train)'])\n",
        "y3 = pd.DataFrame(y_vali, columns=['y_true(validate)'])\n",
        "y4 = pd.DataFrame(y_pred_vali_nn, columns=['y_predict(validate)'])\n",
        "y5 = pd.DataFrame(y_test, columns=['y_true(test)'])\n",
        "y6 = pd.DataFrame(y_pred_test_nn, columns=['y_predict(test)'])\n",
        "Ytrain = pd.concat( [y1,y2], axis=1 )\n",
        "Yvali = pd.concat( [y3,y4], axis=1 )\n",
        "Ytest = pd.concat( [y5,y6], axis=1 )\n",
        "Ytrain.to_csv('2_train_result_lr0.1_mo0.8_SGD_100.csv', index = False) \n",
        "Yvali.to_csv('2_vali_result_lr0.1_mo0.8_SGD_100.csv', index = False)\n",
        "Ytest.to_csv('2_test_result_lr0.1_mo0.8_SGD_100.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}